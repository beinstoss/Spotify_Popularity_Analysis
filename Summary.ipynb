{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Summary.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cH9u_AUX3U3-"
      },
      "source": [
        "#__What Makes a Song Popular?__\n",
        "<img src=\"https://drive.google.com/uc?id=1Ln3Fp-PUu_AUuKY1Wf_oSZ87uxLWAM67\" width=\"600\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eZ2vsKUBFqp"
      },
      "source": [
        "##Motivations\n",
        "Our team is composed of music lovers; Travis plays the guitar, Bryan plays the drums, and Aidas is probably a great singer (TBD)... We're basically a band. This is what made the idea of analyzing musical data so intriguing. We all enjoy music, but the quantifiable data found within each wave length caught our attention."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjLWtSS63WlO"
      },
      "source": [
        "##Objective\n",
        "Through our analysis, we aim to identify the song features that contribute most to a **song's popularity**. In this project, we utilized a third party library named [Spotipy](https://spotipy.readthedocs.io/en/2.16.1/) to interact with the [Spotify API](https://developer.spotify.com/documentation/web-api/), which allows us to access their vast database of songs as well as the metadata tied to each song.\n",
        "\n",
        "###Spotify's Popularity Metric\n",
        "\n",
        "It is important to note that Spotify's popularity rating is based on total number of plays compared to other tracks, as well as how recent those plays are. Our data does not include number of times a song has been played. Instead, our aim is to find ways to **predict** the popularity of a song without taking the number of plays into consideration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRhXwloJ3aqR"
      },
      "source": [
        "#Data Dictionary\n",
        "\n",
        "Field|Data type|Description\n",
        "-------|---------|---------\n",
        "__id__ |integer| Primary key (unique ID for each song) \n",
        "__artist_song__| String | Composite primary key consisting of  a concatenation of `artist` and `track_name` field \n",
        "__pop_category__ | Category | Categorical field used to bucket songs by popularity. Categories include: Low, Mid, High, Very High\n",
        "__artist__| String | Artist name\n",
        "__track_name__| String | Name of song\n",
        "__tempo__| Integer | Beats per minute of a song\n",
        "__time_signature__| String | Time signaure of a song\n",
        "__year__| Integer | Year that a song is released\n",
        "__duration_mins__| String | Duration of a song in minutes\n",
        "__popularity__| Float | The popularity rating is based on total number of plays \n",
        "||compared to other tracks as well as  how recent those plays are. Measured as a value between 0 - 100\n",
        "__acousticness__| Float | A confidence measure from 0 to 100 of whether the track is acoustic.\n",
        "||100 represents high confidence the track is acoustic.\n",
        "__danceability__| Float | Describes how suitable a track is for dancing based on a combination of musical elements including tempo, \n",
        "||rhythm stability, beat strength, and overall regularity. A value of 0 is least danceable and 100 is most danceable.\n",
        "__energy__| Float | Energy is a measure from 0 to 100 and represents a perceptual measure of intensity\n",
        "|| and activity. Typically, energetic tracks feel fast, loud, and noisy.\n",
        "__instrumentalness__ | Float | Predicts whether a track contains no vocals. “Ooh” and “aah” sounds are treated as instrumental in this context. \n",
        "|| Rap or spoken word tracks are clearly “vocal”. The closer the instrumentalness value is to 100, the greater likelihood the track contains no vocal content.\n",
        "__liveness__| Float | Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live.\n",
        "|| A value above 80 provides strong likelihood that the track is live.\n",
        "__loudness__| Float | Confidence measure from 0 - 100 that measures how loud a song is in terms of decibles\n",
        "__speechiness__| Float | Speechiness detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry),\n",
        "||the closer to 100 the attribute value. Values above 66 describe tracks that are probably made entirely of spoken words.\n",
        "__valence__| Float | Confidence measure from 0 - 100 that measures the mood of a song (100 = happy, 0 = sad)\n",
        "\n",
        "__Unused fields:__\n",
        "\n",
        "Field|Description\n",
        "------|------\n",
        "__url__|url to spotify song page\n",
        "__track_href__|A link to the Web API endpoint providing full details of the track.\n",
        "__type__|\"audio_feature\" tag\n",
        "__uri__| Unique indicator for a song within the Spotify platform\n",
        "__analysis_url__|\tAn HTTP URL to access the full audio analysis of this track. An access token is required to access this data.\n",
        "__key__|Musical key in which a song is in\n",
        "__mode__|Mode indicates the modality (major or minor) of a track, the type of scale from which its melodic content is derived. Major is represented by 1 and minor is 0.\n",
        "__duration_ms__| Duration of song in milliseconds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiSwwjY_hLNE"
      },
      "source": [
        "#Raw Data Overview\r\n",
        "------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmomDD7doeE4"
      },
      "source": [
        "## Data Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3bqaly_oMXt"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1qWFdUmFLy-Lvy0bHKvhA7La_6G4myRoA\" width=\"800\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLXEK75Mqk-M"
      },
      "source": [
        "## Null Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhqBY-s5o-c0"
      },
      "source": [
        "Field              |Missing Values\r\n",
        "-------------------|---------------\r\n",
        "artist             | 0\r\n",
        "genre              | 0\r\n",
        "id                 | 0\r\n",
        "popularity         | 0\r\n",
        "track_name         | 0\r\n",
        "year               | 0\r\n",
        "acousticness       | 2\r\n",
        "analysis_url       | 2\r\n",
        "danceability       | 2\r\n",
        "duration_ms       | 2\r\n",
        "energy             | 2\r\n",
        "instrumentalness   | 2\r\n",
        "key                | 2\r\n",
        "liveness           | 2\r\n",
        "loudness           | 2\r\n",
        "mode               | 2\r\n",
        "speechiness        | 2\r\n",
        "tempo              | 2\r\n",
        "time_signature     | 2\r\n",
        "track_href         | 2\r\n",
        "type               | 2\r\n",
        "uri                | 2\r\n",
        "valence            | 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "la0SYhe2q1EC"
      },
      "source": [
        "#Pre-processing\r\n",
        "----------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VU5vRoUOttLs"
      },
      "source": [
        "<u>__Goals__</u>: \r\n",
        "- Remove/clean \r\n",
        "- Normalize  \r\n",
        "- Transform \r\n",
        "- Apply categorical tags"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJAS8U8Ht6EV"
      },
      "source": [
        "## Data removal, normalization & index setting\r\n",
        "In this step we dropped 7 fields that were deemed unnecessary for our analysis, removed null data, generated a unique composite key (_Artist_ + _Track Name_), and normalized our data all song features to be values between 0-100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfZO1jFet9B3"
      },
      "source": [
        "## Genre tagging\r\n",
        "This step focuses on generalizing the genre tagging for each song to aid our analysis. The original genre tagging that was pulled for each song was very specific and difficult to utilize. There were also various genre tags available for each song. Our approach to this was to only pull the first instance of genre within each song's list and then apply the below code to generalize the tagging. By generalizing the genre tags for each song, we will be able to run more efficient aggregations throughout our analysis.\r\n",
        "\r\n",
        "--------------------------------------\r\n",
        "\r\n",
        "<u>Example of raw pull for Genre</u>:\r\n",
        "\r\n",
        "Song|Genre\r\n",
        "----|----\r\n",
        "ABC | ['pop','emo pop', '2000s pop']\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESo1oEFIuLX7"
      },
      "source": [
        "## Popularity classification\r\n",
        "This step is focused on generating popularity classification tags with the following logic:\r\n",
        "```\r\n",
        "if popularity < 60:\r\n",
        "  pop_category = '01 - low'\r\n",
        "elif popularity >= 60 & popularity < 75:\r\n",
        "  pop_category = '02 - mid'\r\n",
        "elif popularity >= 75 & popularity < 90:\r\n",
        "  pop_category = '03 - high'\r\n",
        "elif popularity >= 90:\r\n",
        "  pop_category = '04 - very high'\r\n",
        "  ```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kpBK8y6wuQXL"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1BZuLQXOAkJG68rWcvvKuavaeP1hauKqD\" width=\"450\" height=\"300\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_8hONLJ2ESt"
      },
      "source": [
        "## Outlier Removal\r\n",
        "In this section we examine the extent to which outliers are present in the dataset using a boxplot.  After examination, and upon finding outliers, a data cleaning methodology was implemented.  A function was created with the following steps:\r\n",
        "* Determine the .25 quartile of the data within a given column (using np.quantile).  We call this variable 'Q1'.\r\n",
        "* Determine the .75 quartile of the data within a given column (using np.quantile).  We call this variable 'Q3'.\r\n",
        "* Calculate the IQR as: IQR = Q3 - Q1\r\n",
        "* Calculate an upper bound: UB = Q3 + IQR * 1.5\r\n",
        "* Calculate a lower bound: LB = Q1 - IQR * 1.5\r\n",
        "* Use np.where() to replace high and low outliers with upper bound, and lower bound, respectively.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgpKJokD3l67"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1Fw4Ba9boDJn4MX-zWK_Zdm6RNVMmVlt_\" width=\"450\" height=\"350\">\r\n",
        "\r\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1czUbTsYDlNvniHjFTHdX46V2b1o9N_sc\" width=\"450\" height=\"350\">\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1QDvjZq5nqyR"
      },
      "source": [
        "## Post-Preprocessing Data Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvGfExsqhQ7P"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=14L0nO-cEnZv4idUaqJuKs7L49h0SBRfP\" width=\"800\">\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ea0JlxuqslB"
      },
      "source": [
        "## Preprocessing Shape Impact\r\n",
        "\r\n",
        "Field|Raw Data|Processed Data|Change\r\n",
        "-----|---|-------|----------\r\n",
        "Row Count|13,404|12,571|-833\r\n",
        "Column Count|26|19|-7\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gTJBdbJLAhM4"
      },
      "source": [
        "#Begin Analysis\r\n",
        "------------\r\n",
        "##Test Correlations Between Features\r\n",
        "1. __High__ correlation between a predictor and the target is __preferred__ - we use the correlation as the agent of _relatedness_ between the two;\r\n",
        "  - If Correlation between features > +-.3 = __Good Correlation__\r\n",
        "  - If Correlation between features > +-.5 = __Strong Correlation__\r\n",
        "\r\n",
        "\r\n",
        "2. __Low__ correlation between a pair of predictors is __preferred__ - if you include a pair of highly correlated predictors in the same model, it would cause a problem of _auto-correlation_ or _multi-collinearality_, which would negatively impact the model performance.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1cKZhKIC6f_"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1TL22YyzXk7XfU2z_X9wtNrqyP68p9EnF\" width=\"800\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r2vF5EbtDYlP"
      },
      "source": [
        "##Correlation of Features vs Popularity\r\n",
        "\r\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1w_H_5EvVnDyGVq4OB2_Bnp8NjyETJV6_\" width=\"250\" height=\"300\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJPtBOZDD7Lq"
      },
      "source": [
        "##Test correlation of relevant features against popularity\r\n",
        "\r\n",
        "Feature|Correlation to Popularity\r\n",
        "-------|-----------\r\n",
        "Speechiness|Positive\r\n",
        "Valence|Positive\r\n",
        "Danceability|Positive\r\n",
        "Liveness|Negative\r\n",
        "Acousticness|Negative\r\n",
        "duration_mins|Negative\r\n",
        "Loudness|Neutral\r\n",
        "Enegry|Neutral\r\n",
        "Tempo|Neutral\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLzKIxb7EC4T"
      },
      "source": [
        "\r\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=16b9GO2PK9K-oksaBaPJWJ2YBS3b55Gel\" width=\"400\" height=\"300\">\r\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1ONC5VI5PO6UxcFFunP8GNrtzzQ990I4u\" width=\"400\" height=\"300\">\r\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1e7L11_2iPZsERzSG--jjZFjB4pp907jV\" width=\"400\" height=\"300\">\r\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=19Y-z8eyDHDnfTuKnXDc_tmHXNdc3PXwS\" width=\"400\" height=\"300\">\r\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1uYXiBcsX2ZaRYTH9_0py5svagM7RPE3B\" width=\"400\" height=\"300\">\r\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=19MGCK0SG-nLW4UZCBZ4auy-FbkdR3i5k\" width=\"400\" height=\"300\">\r\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1MI7y_4ob69FqR42ZyCTQNSSAjre54O7K\" width=\"400\" height=\"300\">\r\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1o3VK6TmyYYPX7duvwLFI-PGkRu1_iOSu\" width=\"400\" height=\"300\">\r\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1e5FrpZjeh_x2A0TZ5L4fKnWoS_05-ePV\" width=\"400\" height=\"300\">\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7Sov-1lTsse"
      },
      "source": [
        "# Feature Correlations by Genre\r\n",
        "\r\n",
        "After our initial analysis of how popularity correlates with the various features within our dataset, we decided to go one dimension deeper and look at the same correlations aggregated by genres. \r\n",
        "\r\n",
        "Our hypothesis was that some features would have stronger correlations with popularity when compared to similar types of music. For example, we thought that Rock or Country songs would have strong correlation between popularity and instrumentallness. \r\n",
        "\r\n",
        "The only impactful changes in correlations were seen within the Reggae genre, but this genre only contains 70 samples within our data set, while other genres hold +2,000 samples. This brings us to the conclusion that our initial correlation analysis is not improved by grouping our data by genre.\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtB-ERblIJ1b"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1_v8VLIYjVJoSvbN0APMFpFfTJKF7eaz4\" width=\"500\" height=\"400\">\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYcVmhq7UuY0"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1jh8JJ-tkqxsgNIvDaJaQSICaVmuyZr-p\" width=\"600\" height=\"500\">\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMfwytNNVOQl"
      },
      "source": [
        "# Machine Learning\n",
        "\n",
        "The 3 highest correlated features were sliced and sent to a csv format for machine learning.  The target features were twofold.  For prediction algorithms, the continous feature, popularity, was targeted.  For the classification algorithm, the popularity category feature, one that was created using np.select, was targeted.\n",
        "\n",
        "The following machine learning widget was used:\n",
        "\n",
        "[Wolfram Machine Learning for Small Datasets](https://www.wolframcloud.com/obj/philip/ai)\n",
        "\n",
        "Several prediction algorithms were utilized, and the results were as follows:\n",
        "\n",
        "## Performance Matrix - Prediction\n",
        "| Algorithm | Mean Avg Dev (MAD) |\n",
        "| -------------- | -------------- |\n",
        "| Linear Regression | 6.63 |\n",
        "| Random Forest | 7.01 |\n",
        "| Grad Boosted Tree | 7.65 |\n",
        "| Decision Tree | 7.74 |\n",
        "| Nearest Neighbors | 7.79 |\n",
        "| Neural Network | 7.80 |\n",
        "| Naive (Average) | 8.06 |\n",
        "| Guassian Process | 8.14 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8oBgV7ODVnj6"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1Zg46IHQPLqEmQpJqnpadLgPemOWvDiHv\" width=\"600\" height=\"300\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGXB4OKNV7pc"
      },
      "source": [
        "### Machine Learning Performance over iterations\n",
        "In this area we look at how the machine learning \"learns\" as it iterates through the dataset.  This is achieved by plotting the running MAD vs the iteration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkfFPLp2WLxd"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=14vnzylp_I42yOobj9skPSiHcp043LxsF\" width=\"500\" height=\"400\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o2nTDiLYWgSi"
      },
      "source": [
        "## Classification Results\n",
        "\n",
        "Additionally, a classification algorithm was used to predict the popularity category (very high, high, medium, low).  The decision tree algorithm was used, and it predicted correctly __80.6%__ of the time.  Below you can see the plotted prediction accuracy vs iteration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVtWvKBLWhqz"
      },
      "source": [
        "<img src=\"https://drive.google.com/uc?export=view&id=1kgsys0sH3MohgS591jTgr45tr_1kTO02\" width=\"500\" height=\"400\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GDVqc3wR3YrE"
      },
      "source": [
        "# Challenges\n",
        "**Pulling Data** - Since we chose to build our data set instead of a pre-made one, we spent some time learning how to utilize the Spotify API, adjusting the functions within the Spotipy library for our needs and understanding the features that we have access to.\n",
        "\n",
        "**Correlation Analysis** - Analyzing the correlation between each feature can be a time consuming task and may not be easy to present if the analysis is spread across many cells in the notebook. We overcame this challenge by utilizing a correlation table that aggregates all of the findings into one image.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5cQ_Zw-VB8h"
      },
      "source": [
        "# Conclusion\r\n",
        "------------------\r\n",
        "\r\n",
        "From our analysis, we can make certain general conclusions (as an addition to our machine learning findings). By focusing our study on the various quantifiable features of songs, we can conclude that:\r\n",
        "\r\n",
        "Higher values of danceability, energy, and loudness translate to songs being percieved as \"happier\" (high Valence values). From our analysis, we also saw that the most popular songs have _high_ Valence values compared to the rest, which allows us to make the observation that __up-beat danceable songs that make people feel happy have the highest chance of becoming popular__.\r\n",
        "\r\n",
        "- The __pop genre__ usually contains these characteristics, which correlates with our result that shows pop as being the genre with the highest average popularity rating.\r\n",
        "\r\n",
        "## __Secret Formula:__\r\n",
        "__IF -->__ <img src=\"https://drive.google.com/uc?export=view&id=1FDQeAbmtVOe3JJBAU4RGbTEjbSTzLEdW\" width=\"200\" height=\"175\"> __THEN -->__  <img src=\"https://drive.google.com/uc?export=view&id=1viPiBsCpMepbHmP-jbJKlRTmASUWzWQW\" width=\"200\" height=\"175\">\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NwgBwf-EUFYA"
      },
      "source": [
        "## Potential Next Steps\r\n",
        "Building off our general conclusion, we could expand the analysis by analyzing the _key_ of each song in relation to Valence values. This could be a valuable addition because songs using \"major\" keys tend to have a happier feeling, and vice versa for songs in \"minor\" keys.\r\n",
        "\r\n",
        "After further understanding the implications behind Valence values, we could analyze the correlation between songs with high valence values against those with low valence values in terms of how much radio time they get, how many playlists they are included on, and how often they get played at parties.\r\n",
        "\r\n",
        "These extra steps could help solidify our understanding behind why happier songs tend to have higher popularity ratings.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07duhYsh3eTy"
      },
      "source": [
        "#Analysis Links\n",
        "- [Spotify API](https://drive.google.com/open?id=1O_8MlMrTGuMUKN-UABRfWFISvj_50FTe)\n",
        "- [Data Analysis](https://drive.google.com/open?id=1M46CWkHCB4BlqqIhrtbFN3bfX3ieMiHk)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZUjmPDbSq4-"
      },
      "source": [
        "# Sources\n",
        "- Spotify API documentation: https://developer.spotify.com/documentation/web-api/\n",
        "- Spotipy documentation: https://spotipy.readthedocs.io/en/2.16.1/\n"
      ]
    }
  ]
}